---
format:
  revealjs:
    theme: [default, custom.scss]
    slide-number: false
    progress: false
---

```{r setup, message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(DeclareDesign)
library(kableExtra)


# Global options
knitr::opts_chunk$set(echo = FALSE, message = FALSE, 
                      warnings = FALSE, results = "asis")
```


::: {style="text-align: center"}
## Field Experiments II {.center background-color="#ac1455"}

&nbsp;

**POLSCI 4SS3**  
Winter 2024
:::


## Last time {background-color="#FDBF57"}

- We learned about implementing field experients

- Lots of details!

- Sometimes cannot randomly assign `(stepped-wedge design)`

- **Today:** Thinking about how to do better

## Why do better?

::: incremental

- Conducting research is expensive

- Field experiments are **very** expensive

- Even if you had the resources, we have a mandate to do better

:::

## Research ethics

::: incremental

- [**Belmont report:**](https://www.hhs.gov/ohrp/regulations-and-policy/belmont-report/index.html) Benefits should outweigh costs

- **{{< fa book >}}:** Researchers have duties beyond getting review board approval

- At a minimum, participating in a study takes time

- **Mandate:** Find the most efficient, ethical study before collecting data

- Sometimes that means doing more with a *smaller sample*

:::

# Improving Precision

## Two ways to improve precision

$$
SE(\widehat{ATE}) =\\ \sqrt{\frac{\text{Var}(Y_i(0)) + \text{Var}(Y_i(1)) + 2\text{Cov}(Y_i(0), Y_i(1))}{N-1}}
$$

## Two ways to improve precision

$$
SE(\widehat{ATE}) =\\ \sqrt{\frac{\text{Var}(Y_i(0)) + \text{Var}(Y_i(1)) + 2\text{Cov}(Y_i(0), Y_i(1))}{\color{#ac1455}{N-1}}}
$$

- Increase sample size {{< fa arrow-right >}} Make **denominator** larger 


## Two ways to improve precision

$$
SE(\widehat{ATE}) =\\ \sqrt{\frac{\color{#ac1455} {\text{Var}(Y_i(0)) + \text{Var}(Y_i(1)) + 2\text{Cov}(Y_i(0), Y_i(1))}}{N-1}}
$$

- Alternative research design {{< fa arrow-right >}} Make **numerator** smaller

## Pre-post design

. . .

- Outcomes are measured *at least* twice

- Once before treatment, once after treatment

. . .


```{r}
prepost = tribble(
  ~Condition, ~T1, ~Treatment, ~T2,
  "\\(Z_i=1\\)", "\\(Y_{i, t=1}\\)", "X", "\\(Y_{i, t=2}(1)\\)",
  "\\(Z_i=0\\)", "\\(Y_{i, t=1}\\)", " ", "\\(Y_{i, t=2}(0)\\)"
)

colnames(prepost) = c("Condition", "\\(t=1\\)", "Treatment", "\\(t=2\\)")

prepost %>% kbl(escape = FALSE, align = "llcl")
```

::: aside
AKA repeated measures design
:::


## How does this work?

. . .

- Standard ATE estimator:

$$
E[Y_i(1) | Z_i = 1] - E[Y_i(0) | Z_i = 0]
$$

. . .

- Pre-post ATE estimator:

$$
E[(Y_{i,t=2}(1) - Y_{i,t=1}) | Z_i = 1] - E[(Y_{i,t=2}(0) - Y_{i,t=1}) | Z_i = 0]
$$

## How does this work? {visibility="uncounted"}

- Standard ATE estimator:

$$
E[Y_i(1) | Z_i = 1] - E[Y_i(0) | Z_i = 0]
$$

- Pre-post ATE estimator:

$$
E[(Y_{i,t=2}(1) \color{#ac1455} {- Y_{i,t=1}}) | Z_i = 1] - E[(Y_{i,t=2}(0) \color{#ac1455} {- Y_{i,t=1}}) | Z_i = 0]
$$

. . .

- We improve precision by subtracting the variation in the outcome that is unrelated to the treatment

## Reasons to use pre-post design

- To increase precision in ATE estimates

. . .

- Most useful when pre-treatment outcomes correlate highly with post-treatment outcomes

. . .

- Problematic when:

. . .

1. Pre-treatment outcomes correlate with *potential outcomes*
2. Measuring pre-treatment outcomes leads to *attrition*





## Block randomization

::: incremental

- Change how randomization happens

- Group units in *blocks* or *strata*

- Estimate average treatment effect within each

- Aggregate with a weighted average

:::

## How does it work?

. . .

- Within-block ATE estimator:

$$
\widehat{ATE}_b = E[Y_{ib}(1) | Z_{ib} = 1] - E[Y_{ib}(0) | Z_{ib} = 0]
$$

## How does it work?

- Within-block ATE estimator:

$$
\widehat{ATE}_\color{#ac1455}b = E[Y_{i\color{#ac1455}b}(1) | Z_{i\color{#ac1455}b} = 1] - E[Y_{i\color{#ac1455}b}(0) | Z_{i\color{#ac1455}b} = 0]
$$



. . .

- Overall ATE estimator:

$$
\widehat{ATE}_{\text{Block}} = \sum_{b=1}^B \frac{n_b}{N} \widehat{ATE}_b
$$

## Illustration

:::: {.columns}

::: {.column width="60%"}

```{r}
population = data.frame(
  ID = 1:8,
  Block = c(rep(1, 4), rep(2, 4)),
  y0 = c(rep(1:2, 2), rep(3:4, 2)),
  y1 = c(rep(4:5, 2), rep(8:9, 2))
)


kbl(population,
    escape = FALSE,
    col.names = c("ID", "Block", '\\(Y_i(0)\\)', '\\(Y_i(1)\\)')) %>% 
  row_spec(1:4, background = "#dcdcdc")

# Back of the envelope calculation
true_ate = population %>% 
  mutate(diff = y1 - y0) %>% 
  summarize(ate = mean(diff)) %>% 
  .$ate
```

:::

::: {.column width="40%"}

::: incremental
- Potential outcomes *correlate* with blocks

- True $ATE = 4$

- Do 500 experiments

- Compare complete and block-randomized experiment
:::

:::

::::

## Simulation

```{r sims, cache = TRUE}
pop = declare_population(
  N = 8,
  Block = c(rep(1, 4),
            rep(2, 4)),
  Y_Z_0 = c(1,2,1,2,3,4,3,4),
  Y_Z_1 = c(4,5,4,5,8,9,8,9)
  )

inq = declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0))

comp_rand = declare_assignment(Z =complete_ra(N))

block_rand = declare_assignment(Z = block_ra(blocks = Block))

reveal = declare_measurement(Y = reveal_outcomes(Y ~ Z))

comp_est = declare_estimator( Y ~ Z, inquiry = "ATE", label = "Complete randomization")

block_est = declare_estimator(Y ~ Z, blocks = Block, inquiry = "ATE",
                              .method = difference_in_means,
                              label = "Block randomization")

dc = pop + inq + comp_rand + reveal + comp_est

db = pop + inq + block_rand +  reveal + block_est

set.seed(20230314)
simc = simulate_design(dc)
simb = simulate_design(db)

sim = rbind(simc, simb)
```

```{r}
ggplot(sim) +
  aes(x = estimate, color = estimator) +
  geom_vline(xintercept = true_ate, linetype = "dashed") +
  annotate("text", x = true_ate + 0.4, y = 2, 
           label = "True ATE", size = 5) +
  geom_density(linewidth = 2) +
  theme_bw(base_size = 20) +
  theme(legend.position = "bottom") +
  scale_color_viridis_d(labels = c("Block", "Complete")) +
  labs(x = "Estimate", 
       y = "Density",
       color = "Randomization")
```

::: aside
Block randomization yields a narrower distribution of estimates
:::

## Reasons to block randomize

1. To increase precision in ATE estimates

2. To account for possible heterogeneous treatment effects

. . .

- Most useful when blocking variables correlate with potential outcomes

- And it rarely hurts when they do not correlate! `(more in the lab!)`

# Example

## Kalla et al (2018): Are You My Mentor?

::: incremental
- Correspondence experiment with $N = 8189$ legislators in the US

- Send email about fake student seeking advice to become politician

- Cue gender with student's name
:::

::: aside
Also called *audit* experiments since they were originally designed to audit how responsive elected officials are
:::

## Sample email

![](figs/kalla_0.png){fig-align="center"}

## Data strategy

- Block-randomize by legislator's gender `(why?)`

- **Outcomes:** Reply content and length

## Findings {.smaller}

```{r}
kalla = tribble(
  ~Outcome, ~Male, ~Female, ~p,
  "Received reply", 0.25, 0.27, 0.15,
  "Meaningful response", 0.11, 0.13, 0.47,
  "Praised", 0.05, 0.06, 0.17,
  "Offer to help", 0.03, 0.05, 0.09,
  "Warned against running", 0.01, 0.02, 0.14,
  "Substantive advice", 0.07, 0.08, 0.33,
  "Word count (logged)", 1, 1.1, 0.06,
  "Character count", 145, 170, 0.04
)

colnames(kalla) = c("Outcome", "Male Sender", "Female Sender", "p-value")

kalla %>% kbl()
```

. . .

- Why not much difference by gender?

::: aside
Adapted from Table 1
:::


::: {style="text-align: center"}
## Break time! {.center background-color="#D2D755"}

&nbsp;

![](figs/panda_dance.gif){fig-align="center" width="10%" height="10%"} 
:::

::: {style="text-align: center"}
## {{< fa laptop-code >}} Lab {.center background-color="#007096"}
:::
