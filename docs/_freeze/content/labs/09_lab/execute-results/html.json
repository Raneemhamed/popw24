{
  "hash": "1739d2f36e13f6d495ee4021166308d2",
  "result": {
    "markdown": "---\ntitle: \"Lab 7\"\nsubtitle: \"Field experimental designs I\"\nauthor: |\n        | **Name:** Your name here\n        | **Mac ID:** Your Mac ID here\ndate: \"**Due:** Friday, March 10, 5 PM\"\noutput: \n  pdf_document:\n    highlight: espresso\n    fig_caption: yes\nurlcolor: blue\nheader-includes:\n    - \\usepackage{setspace}\n    - \\doublespacing\n    - \\usepackage{float}\n    - \\floatplacement{figure}{t}\n    - \\floatplacement{table}{t}\n    - \\usepackage{flafter}\n    - \\usepackage[T1]{fontenc}\n    - \\usepackage[utf8]{inputenc}\n    - \\usepackage{ragged2e}\n    - \\usepackage{booktabs}\n    - \\usepackage{amsmath}\nfontsize: 12pt\n---\n\n\n\n\n# Non-compliance\n\nThe [Banerjee et al (2021)](https://www.nber.org/system/files/working_papers/w28074/w28074.pdf) reading focuses on the effect of a \"big push\" program to overcome poverty traps. In this program, households in the treatment group are invited to join the program, but they are free to choose not to participate.\n\nThis reflects a common problem in field experiments, participants may not experience the condition intended by researchers. This could be for logistics problems or because people simply reject treatments.\n\nThe consequence is that knowing which condition units were assigned to is not sufficient to characterize potential outcomes anymore. For example, in a two-arm trial, we can now have four different response profiles. The first two columns indicate the condition individuals are assigned to, the rows indicate the condition that participants actually experience:\n\n| Assigned to control | Assigned to treatment | Type         |\n|---------------------|-----------------------|--------------|\n| Receive control     | Receive control       | Never-taker  |\n| Receive control     | Receive treatment     | Complier     |\n| Receive treatment   | Receive control       | Defier       |\n| Receive treatment   | Receive treatment     | Always-taker |\n\n: Potential outcome profiles under non-compliance\n\nIn words:\n\n- Never- and always-takers experience the same condition regardless of treatment assignment\n\n- Compliers go along with what the researcher intends\n\n- Defiers go with the opposite of what the researcher intends\n\nSince they are potential outcomes, compliance types cannot be observed directly. If someone rejects treatment, you do not know if they are defiers or never-takers. \n\nTo simplify potential outcomes, researchers usually assume **one-sided non-compliance**, which implies that units can only deviate from assigned conditions in treatment, but not in control. This would make sense for a field experiment similar to the TUP program, people can choose not to participate in the program if invited, but can't force their way into the program when not invited (at least in theory).\n\nThis means that the only compliance problem to worry about is units rejecting treatment, and whether they are never-takers or defiers becomes irrelevant.\n\nThe following code design simulates a field experiment with one-sided non-compliance. See [Section 18.6](https://book.declaredesign.org/experimental-causal.html#encouragement-designs) of the textbook for details.\n\n\n::: {.cell hash='09_lab_cache/html/unnamed-chunk-1_7bfe83d18885c1469b5f4445a89e05a4'}\n\n```{.r .cell-code}\ncompliance_rate = 0.8\n\n# M\ncomp_model = declare_model(\n  N = 500,\n  U = rnorm(N),\n  # indicate whether respondent would reject treatment if assigned to\n  comply = complete_rs(\n    N = N,\n    prob = compliance_rate\n    ),\n  # potential outcomes with respect to D\n  potential_outcomes(\n    Y ~  0.25 * D + U,\n    conditions = list(D = c(0, 1))\n  ),\n  # potential outcomes with respect to Z\n  potential_outcomes(\n    D ~ case_when(\n      Z == 1 & comply == 1 ~ 1,\n      Z == 1 & comply == 0 ~ 0,\n      Z == 0 ~ 0\n    ),\n    conditions = list(Z = c(0, 1))\n  )\n)\n```\n:::\n\n\nHere we use `Z` to characterize treatment *assignment* and `D` to characterize treatment *reception*. The `compliance_rate` indicates the proportion of units in our sample that would accept treatment if assigned to.\n\nOur inquiry now specifies two quantities of interest. On top of the usual average treatment effect (ATE), we can also calculate the **average treatment effect on the treated (ATT)**.\n\n\n::: {.cell hash='09_lab_cache/html/unnamed-chunk-2_2218a5d734a200ba2eb26bf273e7148e'}\n\n```{.r .cell-code}\n# I\ncomp_inquiry = declare_inquiry(\n  ATE = mean(Y_D_1 - Y_D_0),\n  ATT = mean(Y_D_1[comply == 1] - Y_D_0[comply == 1])\n  )\n```\n:::\n\n\nThe data strategy first assigns `Z` and then realizes `D` and `Y` accordingly.\n\n\n::: {.cell hash='09_lab_cache/html/unnamed-chunk-3_018bc1b63a6b60f6a355ab4d83d325d6'}\n\n```{.r .cell-code}\ncomp_assign = declare_assignment(\n  Z = conduct_ra(N = N)\n  )\n\ncomp_measure = declare_measurement(\n  D = reveal_outcomes(D ~ Z),\n  Y = reveal_outcomes(Y ~ D)\n  )\n```\n:::\n\n\nSince we have two inquiries, we also have two answer strategies. The first is known as the **intention to treat (ITT)** estimator, which is just the difference in means based on treatment assignment. You usually calculate this when you do not observe compliance status but suspect that participants may reject treatment.\n\nThe second is a **local average treatment effect (LATE)**, which tries to factor in both assigned and received treatment to adjust the ITT by the compliance rate. The estimation procedure for this is known as *two-stage least squares* or *instrumental variable*. The details are beyond the scope of this lab.\n\n\n::: {.cell hash='09_lab_cache/html/unnamed-chunk-4_c5c09ef6a475120034363908f7ee9500'}\n\n```{.r .cell-code}\n# A\nitt = declare_estimator(\n  Y ~ Z,\n  inquiry = c(\"ATE\", \"ATT\"),\n  label = \"ITT\"\n)\n\nlate = declare_estimator(\n  Y ~ D | Z,\n  .method = iv_robust,\n  inquiry = c(\"ATE\", \"ATT\"),\n  label = \"LATE\"\n  )\n```\n:::\n\n\nNow, we can put the design together:\n\n\n::: {.cell hash='09_lab_cache/html/unnamed-chunk-5_331cf6d1d0df066112f04b9780ef0e97'}\n\n```{.r .cell-code}\ncomp_design = comp_model + comp_inquiry + \n  comp_assign +  comp_measure +\n  itt + late\n```\n:::\n\n\n\n## TASK 1\n\n**Diagnose the** `comp_design` **and evaluate each answer strategy in terms of bias, RMSE, and power. Which estimator would you recommend using? Why?**\n\n**What happens to the three diagnosands when you decrease the** `compliance_rate` **? Why?**\n\n**What happens to the diagnosands when we have a** `compliance_rate` **equal to 1?**\n\n# Stepped-wedge design\n\n[Pennycook et al (2021)](https://www.nature.com/articles/s41586-021-03344-2) use a stepped-wedge experiment. The following code declares such a design with two conditions and an arbitrary number of time periods or waves.\n\nThe model is a little more involved since each wave is a different level and we observe each units as many times as we have levels.\n\n\n::: {.cell hash='09_lab_cache/html/unnamed-chunk-6_10304107e60c966c6a567e9ef4febe8a'}\n\n```{.r .cell-code}\n# M\nt = 3 # number of periods\n\nswd_model = declare_model(\n  units = add_level(\n    N = 100,\n    U_unit = rnorm(N)\n  ),\n  periods = add_level(\n    N = t,\n    time = 1:max(periods),\n    U_time = rnorm(N),\n    nest = FALSE\n  ),\n  unit_period = cross_levels(\n    by = join_using(units, periods),\n    U = rnorm(N),\n    potential_outcomes(\n      Y ~ scale(U_unit + U_time + time + U) + 0.35 * Z\n      )\n  )\n)\n```\n:::\n\n\nThe inquiry is the usual average treatment effect, but this quantity is not defined at the last time period since by then the control group is empty.\n\n\n::: {.cell hash='09_lab_cache/html/unnamed-chunk-7_9b9942aaf8150a18ed2c96e48a308a3a'}\n\n```{.r .cell-code}\n# I\nswd_inquiry = declare_inquiry(\n  ATE = mean(Y_Z_1 - Y_Z_0), \n  subset = time < max(time)\n)\n```\n:::\n\n\nThe answer strategy assigns in which period a unit receives treatment, then the unit stays treated for the rest of the study.\n\n\n::: {.cell hash='09_lab_cache/html/unnamed-chunk-8_887218288f46904e9390a78b85da27fd'}\n\n```{.r .cell-code}\n# D\nswd_assign =  declare_assignment(\n  wave = cluster_ra(clusters = units, \n                    conditions = 1:max(periods)),\n  Z = if_else(time >= wave, 1, 0)\n  )\n\nswd_measure = declare_measurement(\n  Y = reveal_outcomes(Y ~ Z)\n  )\n```\n:::\n\n\nOur estimator needs to account for how outcome `Y` varies over time and across units in ways that are unrelated to the experiment and that we observe the same units multiple times. This is best done with a regression model with *two-way fixed-effects* and *clustered standard errors* (again, further details are beyond this lab).\n\n\n::: {.cell hash='09_lab_cache/html/unnamed-chunk-9_c402ce490624f97588f6f0d3826ffeda'}\n\n```{.r .cell-code}\n# A\nswd_estimator = declare_estimator(\n  Y ~ Z, \n  fixed_effects = ~ periods + units,\n  clusters = units, \n  subset = time < max(time),\n  inquiry = \"ATE\", \n  label = \"TWFE\") \n```\n:::\n\n\nThen we put the design together:\n\n\n::: {.cell hash='09_lab_cache/html/unnamed-chunk-10_5a253a5ead05b7f103417a7bf82b7a20'}\n\n```{.r .cell-code}\nswd = swd_model + swd_inquiry + swd_assign + swd_measure + swd_estimator\n```\n:::\n\n\n\n## TASK 2\n\n**Diagnose the** `swd` **design with the current number of time periods** `t` **and two more alternative values larger than 3 but less or equal than 10. Looking at bias, RMSE, and power, Which number of time periods would you recommend? Why? Remember that collecting data is costly, so you do not want to have more time periods than necessary.**\n\n# Answers\n\nWrite your answers here. Remember to show the code you use to get the answer!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}